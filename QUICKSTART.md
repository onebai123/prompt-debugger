# 快速开始指南 🚀

## 安装运行

### 1. 克隆项目
```bash
git clone https://github.com/onebai123/prompt-debugger.git
cd prompt-debugger
```

### 2. 安装依赖
```bash
npm install
# 或
yarn install
```

### 3. 启动开发服务器
```bash
npm run dev
# 或
yarn dev
```

### 4. 访问应用
打开浏览器访问：`http://localhost:3000`

## 配置 API

### 方式1：界面配置（推荐）
1. 点击右上角 **⚙️ 配置** 按钮
2. 填写以下信息：
   - **API Base URL**: `https://api.openai.com/v1`
   - **API Key**: 你的API密钥
   - **默认模型**: `gemini-2.0-flash-exp`
3. 点击 **保存配置**

### 方式2：环境变量
1. 复制 `.env.example` 为 `.env.local`
2. 编辑 `.env.local`，填写配置
3. 重启开发服务器

## 基础使用流程

### 1. 创建会话
- 点击 **开始测试** 按钮
- 进入批量测试界面
- 会自动创建"默认会话"

### 2. 输入提示词
在左侧"会话管理"区域：
- 直接在输入框填写你的AI提示词
- 或从文件导入

### 3. 生成测试用例
在"测试用例生成"区域：
- 点击 **AI生成测试用例**
- 设置生成数量（建议10个）
- 选择测试级别（P1+P2推荐）
- 等待AI生成测试用例

### 4. 配置评判标准
在"评判标准"区域：
- 点击 **快速切换**，选择预设标准
- 或点击 **AI生成标准**
- 启用需要的评判标准

### 5. 执行测试
在"执行控制"区域：
- 设置并发数（建议5）
- 点击 **开始测试**
- 实时查看测试进度
- 等待测试完成

### 6. 查看结果
在"测试结果"区域：
- 查看通过率统计
- 展开每个测试用例查看详情
- 点击查看对话历史

### 7. AI评分
在右侧"AI综合评分"面板：
- 自动显示五维度评分
- 查看改进建议
- 分析测试结果

### 8. 优化提示词
在"提示词优化"区域：
- 填写"优化前提"（可选）
- 填写"优化方向"
- 点击 **AI优化**
- 查看优化建议
- 点击 **保存为新版本**

### 9. 版本对比
在"版本管理"区域：
- 切换到新版本（V2）
- 点击 **对比** 按钮
- 查看版本差异
- 重新测试验证效果

### 10. 持续迭代
- 重复步骤5-9
- 不断优化提示词
- 直到达到期望效果

## 高级技巧

### 克隆会话
- 点击会话右侧的 📋 按钮
- 快速复制会话数据
- 用于A/B测试对比

### 重命名会话
- 点击会话右侧的 ✏️ 按钮
- 输入新名称
- 方便组织管理

### 导出数据
- 测试结果自动保存在浏览器
- 支持导出为JSON格式
- 可分享给团队成员

## 常见问题

### Q: 首次使用需要配置什么？
A: 只需配置AI API密钥即可开始使用。

### Q: 数据保存在哪里？
A: 所有数据保存在浏览器LocalStorage，不上传服务器。

### Q: 支持哪些AI模型？
A: 支持所有OpenAI API兼容的服务，如OpenAI、Gemini、Claude等。

### Q: 测试用例可以手动编辑吗？
A: 可以！生成后可以直接修改测试用例内容。

### Q: 如何提高测试通过率？
A: 通过AI评分和优化功能，持续迭代提示词，通常可提升20-40%通过率。

## 下一步

- 查看 [完整文档](README.md)
- 了解 [高级功能](docs/advanced.md)
- 查看 [最佳实践](docs/best-practices.md)

---

遇到问题？提交 [Issue](https://github.com/onebai123/prompt-debugger/issues) 获取帮助！
